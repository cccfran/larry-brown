[
  {
    "name": "Susan Murphy",
    "year": "2024",
    "affiliation": "Harvard University",
    "url": "http://people.seas.harvard.edu/~samurphy/",
    "bio": "Susan A. Murphy is Mallinckrodt Professor of Statistics and of Computer Science and Associate Faculty at the Kempner Institute, Harvard University.  Her research focuses on improving sequential decision making via the development of online, real-time reinforcement learning algorithms.  Her lab is involved in multiple deployments of these algorithms in digital health.  She is a member of the US National Academy of Sciences and of the US National Academy of Medicine.  In 2013 she was awarded a MacArthur Fellowship for her work on experimental designs to inform sequential decision making.  She is a Fellow of the College on Problems in Drug Dependence, Past-President of Institute of Mathematical Statistics, Past-President of the Bernoulli Society and a former editor of the Annals of Statistics.",
    "lectures": [
      {
        "id": 1, 
        "title": "Online Reinforcement Learning in Digital Health Interventions",
        "date": "November 19, 2024",
        "abstract": "In this talk I will discuss first solutions to some of the challenges we face in developing online RL algorithms for use in digital health interventions targeting patients struggling with health problems such as  substance misuse, hypertension and bone marrow transplantation. Digital health raises a number of challenges to the RL community including different sets of actions, each set intended to impact patients over a different time scale;  the need to learn both within an implementation and between implementations of the RL algorithm; noisy environments and a lack of mechanistic models.    In all of these settings the online line algorithm must be stable and autonomous.   Despite these challenges, RL, with careful initialization, with careful management of bias/variance tradeoff and by close collaboration with health scientists can be successful. We can make an impact!"
      },
      {
        "id": 2, 
        "title": "Inference for Longitudinal Data After Adaptive Sampling",
        "date": "November 20, 2024",
        "abstract": "Adaptive sampling methods, such as reinforcement learning (RL) and bandit algorithms, are increasingly used for the real-time personalization of interventions in digital applications like mobile health and education. As a result, there is a need to be able to use the resulting adaptively collected user data to address a variety of inferential questions, including questions about time-varying causal effects. However, current methods for statistical inference on such data (a) make strong assumptions regarding the environment dynamics, e.g., assume the longitudinal data follows a Markovian process, or (b) require data to be collected with one adaptive sampling algorithm per user, which excludes algorithms that learn to select actions using data collected from multiple users. These are major obstacles preventing the use of adaptive sampling algorithms more widely in practice. In this work, we proved statistical inference for the common Z-estimator based on adaptively sampled data. The inference is valid even when observations are non-stationary and highly dependent over time, and (b) allow the online adaptive sampling algorithm to learn using the data of all users. Furthermore, our inference method is robust to miss-specification of the reward models used by the adaptive sampling algorithm. This work is motivated by our work in designing the Oralytics oral health clinical trial in which an RL adaptive sampling algorithm is used to select treatments, yet valid statistical inference is essential for conducting primary data analyses after the trial is over."
      },
      {
        "id": 3, 
        "title": "Replicable Bandits for Digital Health",
        "date": "November 21, 2024",
        "abstract": "Adaptive treatment assignment algorithms, such as bandit and reinforcement learning algorithms, are increasingly used in digital health interventions. Between implementation of the digital health intervention, data analyses are critical for producing generalizable knowledge and deciding how to update the intervention for the next implementation. However the replicability of these between-implementation data analyses has received relatively little attention. This work investigates the replicability of statistical analyses from data collected by adaptive treatment assignment algorithms. We demonstrate that many standard statistical estimators can be inconsistent and fail to be replicable across repetitions of the clinical trial, even as the sample size grows large. We show that this non-replicability is intimately related to properties of the adaptive algorithm itself. We introduce a formal definition of a 'replicable bandit algorithm' and prove that under such algorithms, a wide variety of common statistical analyses are guaranteed to be consistent.  Our findings underscore the importance of designing adaptive algorithms with replicability in mind, especially for settings like digital health where deployment decisions rely heavily on replicated evidence. We conclude by discussing open questions on the connections between algorithm design, statistical inference, and experimental replicability."
      }
    ]
  },
  {
    "name": "David Donoho",
    "year": "2023",
    "affiliation": "Stanford University",
    "url": "https://web.stanford.edu/dept/statistics/cgi-bin/donoho/",
    "bio": "David Donoho has studied the exploitation of sparse signals in signal recovery, including for denoising, superresolution, and solution of underdetermined equations. His research with collaborators showed that ell-1 penalization was an effective and even optimal way to exploit sparsity of the object to be recovered. He coined the notion of compressed sensing which has impacted many scientific and technical fields, including magnetic resonance imaging in medicine, where it has been implemented in FDA-approved medical imaging protocols and is already used in millions of actual patient MRIs.<br><br> In recent years David and his postdocs and students have been studying large-scale covariance matrix estimation, large-scale matrix denoising, detection of rare and weak signals among many pure noise non-signals, compressed sensing and related scientific imaging problems, and most recently, empirical deep learning.",
    "lectures": [
      {
        "id": 1, 
        "title": "Data Science vs Statistics",
        "date": "April 23, 2023",
        "abstract": "A conventional narrative tells us that Data Science is just a rebranding of traditional statistics. This talk explores the idea that there is a “Data Science” mindset derived from modern digital life, and a “Statistics Mindset” derived from long intellectual tradition. These mindsets breed two completely different mental realities ie. different thoughts we can hold in mind and pay attention to. Because of this, there is a gaping divide between what residents of each mental reality can focus upon, produce and value. Downstream of this, two completely separate discourses and cultures are developing.<br><br> In our view, the two sides don’t properly understand that there are two sides, and that severe challenges are caused by this split. This shows up when each camp reflects on the other in frequent frustration, pointless conversations and negative emotions. This can be seen in situations where teams from each side of the divide both do research about the same topic, and try to engage with each other's research. <br><br> It is important for the statistics tradition to drop the blinders and see the situation clearly, to finally benefit from the existence of the data science reality. Similarly, data science could make better progress by clearly understanding what the statistics tradition can offer.<br><br> Finally, the biggest opportunities will come for those who can become bicultural. The talk should be accessible to a broader audience. This is joint work with Matan Gavish (Hebrew University CS)."
      },
      {
        "id": 2, 
        "title": "Widespread Panic over Model Collapse",
        "date": "April 24, 2023",
        "abstract": "Modern ML systems are extraordinarily data hungry; and some major commercial players are said to now be using synthetic data to train their most ambitious ML systems. Also, AI-generated data will soon flood the internet, perhaps to the point where most available data are synthetic. Recently ML research has started to confront the larger issues that synthetic data might pose, including a future where most or all of the data available for an ML training are synthetic. A number of ML papers became prominent after promoting the idea of “model collapse”, the “curse of recursion”, “model autophagy disorder”. Featuring experiments and some very basic theoretical argumentation they promoted a storyline where successive recycling of purely synthetic data led to model degeneration. <br><br>In contrast, Mathematical Scientists have looked at the same setting as the ML researchers, and developed a more balanced view of the situation, depending on the synthetic data use case, no such collapse occurs. Empirical work with canonical LLMs and diffusion models confirms the absence of collapse, in the recommended use case. <br><br>I will review the setting, the narrative promoting to panic and counter narratives leading to a calmer view. The talk should be accessible to a broader audience, as most of the research in this area consists of analysis at the statistics undergraduate major or master’s level — although one could transplant the basic questions into fancier settings if one liked. <br><br> This is joint work with Apratim Dey of Stanford Statistics and a CS team at Stanford."
      },
      {
        "id": 3, 
        "title": "Optimal Vector Sensing by Stein Shrinkage",
        "date": "April 25, 2023",
        "abstract": "We review some Compressed Sensing theory through the lens of Approximate Message Passing, and minimax decision theory concerning shrinkage estimates. AMP powers up a simple estimator for an elementary problem into a procedure for a drastically more ambitious problem of compressed sensing. In this case the simple estimator is James-Stein shrinkage and we use it to construct a procedure of multiple measurement vector compressed sensing. <br><br> We discuss the State Evolution analysis of this procedure, prove and empirically verify all the predictions of state evolution, and so on. We discuss the state evolution theory of Compressed Sensing in the sense of sparsity-undersampling phase diagram. In the large dimensional limit both in system size and vector size, with Gaussian sensing matrices, James-Stein has a theoretically unimprovable phase diagram and empirically works near-optimally even in low vector dimensions. In particular this is far better than the convex optimization approaches. <br><br> This is joint work with Apratim Dey (Stanford Statistics)."
      }
    ]
  },
  {
    "name": "Iain Johnstone",
    "affiliation": "Stanford University",
    "bio": "Dr. Johnstone is a statistician with research interests in statistical decision theory and wavelet-like methods (and their uses) in estimation theory, asymptotics and application areas such as statistical inverse problems and statistical signal processing. Other interests include simulation methodology, volume tests of significance, hazard rate estimation and maximum entropy methods.",
    "year": "2022",
    "url": "https://imjohnstone.su.domains",
    "lectures": [
      {
        "id": 1, 
        "title": "Estimating Sparse Eigenstructure for High Dimensional Data",
        "date": "November 16, 2022",
        "abstract": "When data is high dimensional, widely used multivariate methods such as principal component analysis can behave in unexpected ways. Upward bias in sample eigenvalues and inconsistency of sample eigenvectors are among the new phenomena that appear. In this expository overview talk, I will try to use (amateur!) graphics and heuristic arguments to explain how these phenomena arise, and some of the things that can be done in response."
      },
      {
        "id": 2, 
        "title": "Likelihood Ratios and a Transition from Gaussian to Tracy-Widom",
        "date": "November 17, 2022",
        "abstract": "The Tracy-Widom distribution has found broad use in statistical theory and application. We first review some of this, focusing first on Principal Components Analysis and the `spiked model`. When the spike signal is below the Baik-Ben Arous-Peche threshold, likelihood ratio tests for presence of a spike are more efficient than the largest eigenvalue in many settings of multivariate statistics. In recent work in a spiked Wigner model with Egor Klochkov, Alexei Onatski and Damian Pavlyshyn, we study the likelihood ratio test in the transition zone around the BBP threshold, making use of a connection with the spherical Sherrington-Kirkpatrick model and establishing a conjecture of Baik and Lee."
      },
      {
        "id": 3, 
        "title": "Expectation Propagation in Mixed Models",
        "date": "November 18, 2022",
        "abstract": "Matt Wand and colleagues have recently shown that the machine learning technique of expectation propagation (EP) yields state of the art estimation of parameters in generalized linear mixed models. We review this work before asking: are the EP estimators asymptotically efficient? The problem becomes one of defining an appropriate objective function that captures the EP iteration and approximates maximum likelihood well enough to inherit its efficiency. Joint work with the late Peter Hall, Song Mei, and Matt Wand."
      }
    ]
  },
  {
    "name": "Jim Berger",
    "bio": "Berger received his Ph.D. degree in mathematics from Cornell University in 1974. He was a faculty member in the Department of Statistics at Purdue University until 1997, at which time he moved to the Institute of Statistics and Decision Sciences (now the Department of Statistical Science) at Duke University, where he is currently the Arts and Sciences Professor of Statistics. He was the founding director of the Statistical and Applied Mathematical Sciences Institute, serving from 2002-2010.<br><br>Berger was president of the Institute of Mathematical Statistics during 1995-1996, chair of the Section on Bayesian Statistical Science of the American Statistical Association in 1995, and president of the International Society for Bayesian Analysis during 2004. He has been involved with numerous editorial activities, including co-editorship of the Annals of Statistics during the period 1998-2000 and being a founding editor of the Journal on Uncertainty Quantification, serving from 2012-2015.<br><br> Among the awards and honors Berger has received are Guggenheim and Sloan Fellowships, the COPSS President's Award in 1985, the Sigma Xi Research Award at Purdue University for contribution of the year to science in 1993, the COPSS Fisher Lecturer in 2001, the Wald Lecturer of the IMS in 2007 and the Wilks Award from the ASA in 2015. He was elected as foreign member of the Spanish Real Academia de Ciencias in 2002, elected to the USA National Academy of Sciences in 2003, was awarded an honorary Doctor of Science degree from Purdue University in 2004, and became an Honorary Professor at East China Normal University in 2011.<br><br> Berger's research has primarily been in Bayesian statistics, foundations of statistics, statistical decision theory, simulation, model selection, and various interdisciplinary areas of science and industry, including astronomy, geophysics, medicine, and validation of complex computer models. He has supervised 36 Ph.D. dissertations, published over 190 papers and has written or edited 16 books or special volumes.",
    "affiliation": "Duke University",
    "year": "2021",
    "url": "http://www2.stat.duke.edu/~berger/",
    "lectures": [
      {
        "id": 1, 
        "title": "Emulation of Computer Models with Massive Output",
        "date": "September 8, 2021",
        "abstract": "Often computer models yield massive output; e.g., a weather model will yield the predicted temperature over a huge grid of points in space and time. Emulation of a computer model is the process of finding an approximation to the computer model that is much faster to run than the computer model itself (which can often take hours or days for a single run). Many successful emulation approaches are statistical in nature. We discuss one such approach – the construction of independent parallel emulators at each grid point – with the emulators being developed through Gaussian processes. The computational simplicity with which this approach can be implemented will be highlighted and the surprising fact that one can ignore spatial structure in the massive output will be explained. All results will be illustrated with a computer model of volcanic pyroclastic flow, the goal being the prediction of hazard probabilities near active volcanoes."
      },
      {
        "id": 2, 
        "title": "Four Types of Frequentism and Their Interplay with Bayesianism",
        "date": "September 9, 2021",
        "abstract": "The majority of statisticians and scientists who use statistics declare themselves to be frequentists, but they typically mean very different things by this declaration. The purpose of this talk is to highlight the major different types of frequentists and to indicate which are compatible with Bayesianism and which are not. The focus is on evaluating common statistical procedures from the different perspectives, primarily from three unconditional frequentist perspectives."
      },
      {
        "id": 3, 
        "title": "The Conditional Frequentist Principle and Data Dependent Error Probabilities",
        "date": "September 10, 2021",
        "abstract": "The majority of statisticians and scientists who use statistics declare themselves to be frequentists, but they typically mean very different things by this declaration. This talk is a continuation of Talk 2 on the subject, with the focus shifting to the conditional frequentist perspective, rather than the unconditional frequentist perspective; it is not necessary to have been at the previous talk to follow this one. Larry Brown’s significant work in this area will be highlighted."
      }
    ]
  } 
]
